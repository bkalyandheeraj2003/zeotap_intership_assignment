{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde7f783-bb92-4e92-9577-2b461d19684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d1ed5c0-e5e2-436c-96f6-22705953afce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data.csv already exists. Skipping download.\n",
      "All datasets processed.\n"
     ]
    }
   ],
   "source": [
    "#loading our dataset\n",
    "def download_data(url, output):\n",
    "    gdown.download(url, output, quiet=False)\n",
    "\n",
    "# Google Drive link for the merged_data.csv\n",
    "file_url = \"https://drive.google.com/file/d/1Oa62mOYcNhQEycOxyBFyrPkSfScA20zn/view?usp=sharing\"\n",
    "file_output = \"merged_data.csv\"  # Corrected: Assign the filename as a string\n",
    "\n",
    "# Convert to a direct download link\n",
    "file_id = file_url.split('/d/')[1].split('/view')[0]\n",
    "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.isfile(file_output):\n",
    "    print(f\"Downloading {file_output}...\")\n",
    "    download_data(download_url, file_output)\n",
    "else:\n",
    "    print(f\"{file_output} already exists. Skipping download.\")\n",
    "\n",
    "print(\"All datasets processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6dd8237-8adb-49e5-bc5d-ce00639e93f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "- Average Top-3 Similarity: 0.9814\n",
      "- Variance in Similarity Scores: 0.0003\n",
      "- Silhouette Score: 0.2698\n",
      "Lookalike.csv created at: /mnt/data\\Lookalike.csv\n"
     ]
    }
   ],
   "source": [
    "# Suppress unnecessary warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Load the dataset\n",
    "merged_data = pd.read_csv(\"merged_data.csv\")\n",
    "\n",
    "# Feature Engineering: Add Recency, Frequency, and Monetary Value\n",
    "merged_data['TransactionDate'] = pd.to_datetime(merged_data['TransactionDate'])\n",
    "latest_date = merged_data['TransactionDate'].max()\n",
    "merged_data['Recency'] = (latest_date - merged_data['TransactionDate']).dt.days\n",
    "frequency_data = merged_data.groupby('CustomerID')['TransactionID'].count().reset_index()\n",
    "frequency_data.rename(columns={'TransactionID': 'Frequency'}, inplace=True)\n",
    "merged_data = merged_data.merge(frequency_data, on='CustomerID', how='left')\n",
    "merged_data['MonetaryValue'] = merged_data['TotalValue']\n",
    "\n",
    "# Select relevant features for similarity calculation\n",
    "features = [\n",
    "    'Quantity', 'TotalValue', 'AvgPricePerItem', 'CustomerLifetimeValue',\n",
    "    'Recency', 'Frequency', 'MonetaryValue'\n",
    "]\n",
    "\n",
    "# Data preprocessing: Group data by CustomerID\n",
    "customer_profiles = merged_data.groupby('CustomerID')[features].mean().reset_index()\n",
    "\n",
    "# Fill missing values (if any) with zeros\n",
    "customer_profiles.fillna(0, inplace=True)\n",
    "\n",
    "# Normalize the feature matrix\n",
    "scaler = StandardScaler()\n",
    "feature_matrix = scaler.fit_transform(customer_profiles[features])\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=3)  # Reduce to 3 components for better clustering\n",
    "pca_matrix = pca.fit_transform(feature_matrix)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_matrix = cosine_similarity(pca_matrix)\n",
    "\n",
    "# Prepare to store lookalikes\n",
    "lookalike_map = {}\n",
    "\n",
    "# Find top 3 lookalikes for each customer\n",
    "average_top3_similarity = []  # Track average similarity for top 3 recommendations\n",
    "for idx, customer_id in enumerate(customer_profiles['CustomerID']):\n",
    "    # Get similarity scores for the current customer\n",
    "    similarity_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    \n",
    "    # Exclude the customer themselves and sort by similarity\n",
    "    similarity_scores = sorted(\n",
    "        [(i, score) for i, score in similarity_scores if i != idx],\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    \n",
    "    # Get the top 3 most similar customers\n",
    "    top_3 = similarity_scores[:3]\n",
    "    \n",
    "    # Calculate average similarity for the top 3 recommendations\n",
    "    average_top3_similarity.append(np.mean([score for _, score in top_3]))\n",
    "    \n",
    "    # Map customer_id to the top 3 lookalike customer IDs and their scores\n",
    "    lookalike_map[customer_id] = [(customer_profiles['CustomerID'].iloc[i]) for i, score in top_3]\n",
    "\n",
    "# Create Lookalike.csv for customers C0001 to C0020\n",
    "lookalike_list = []\n",
    "for customer_id in customer_profiles['CustomerID']:\n",
    "    if customer_id in [f'C{str(i).zfill(4)}' for i in range(1, 21)]:\n",
    "        lookalike_list.append({\n",
    "            'CustomerID': customer_id,\n",
    "            'Lookalikes': lookalike_map[customer_id]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame and save to CSV\n",
    "lookalike_df = pd.DataFrame({\n",
    "    'CustomerID': [row['CustomerID'] for row in lookalike_list],\n",
    "    'Lookalike_Map': [row['Lookalikes'] for row in lookalike_list]\n",
    "})\n",
    "\n",
    "# Cluster the feature matrix for silhouette score calculation\n",
    "n_clusters = 5  # Adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(pca_matrix)\n",
    "\n",
    "# Evaluate quality of recommendations\n",
    "avg_similarity = np.mean(average_top3_similarity)\n",
    "similarity_variance = np.var(average_top3_similarity)\n",
    "silhouette_avg = silhouette_score(pca_matrix, cluster_labels)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"- Average Top-3 Similarity: {avg_similarity:.4f}\")\n",
    "print(f\"- Variance in Similarity Scores: {similarity_variance:.4f}\")\n",
    "print(f\"- Silhouette Score: {silhouette_avg:.4f}\")\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_dir = '/mnt/data'\n",
    "output_path = os.path.join(output_dir, 'Lookalike.csv')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "lookalike_df.to_csv(output_path, index=False)\n",
    "print(f\"Lookalike.csv created at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a5f2c3-4b82-451c-b925-00f9b956e1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"lookalike.csv\" download>lookalike.csv (Click to Download)</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloading csv file to local computer\n",
    "\n",
    "# Save the merged_data to a CSV file\n",
    "csv_filename = \"lookalike.csv\"\n",
    "lookalike_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Generate a download link for the CSV file\n",
    "def create_download_link(filename):\n",
    "    \"\"\"\n",
    "    Creates a downloadable link for a given file.\n",
    "        HTML: HTML link to download the file.\n",
    "    \"\"\"\n",
    "    return HTML(f'<a href=\"{filename}\" download>{filename} (Click to Download)</a>')\n",
    "\n",
    "# Display the download link\n",
    "create_download_link(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa24c6-dbe6-4e26-85c9-f8626a091bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c1e9c-71d2-4f99-bf4f-14ab29204af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
